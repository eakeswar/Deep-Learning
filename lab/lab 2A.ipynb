{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **# Implemetation of ANN without regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### # Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28), Training labels shape: (60000,)\n",
      "Testing data shape: (10000, 28, 28), Testing labels shape: (10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to the range [0,1]\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"Training data shape: {x_train.shape}, Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing data shape: {x_test.shape}, Testing labels shape: {y_test.shape}\")\n",
    "\n",
    "# Visualizing some training images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(x_train[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eakes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 0.4366 - val_accuracy: 0.9592 - val_loss: 0.1386\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9633 - loss: 0.1255 - val_accuracy: 0.9674 - val_loss: 0.1049\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9746 - loss: 0.0821 - val_accuracy: 0.9738 - val_loss: 0.0875\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9825 - loss: 0.0572 - val_accuracy: 0.9743 - val_loss: 0.0791\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9874 - loss: 0.0421 - val_accuracy: 0.9753 - val_loss: 0.0765\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9897 - loss: 0.0324 - val_accuracy: 0.9760 - val_loss: 0.0823\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0279 - val_accuracy: 0.9791 - val_loss: 0.0685\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0217 - val_accuracy: 0.9788 - val_loss: 0.0719\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9953 - loss: 0.0164 - val_accuracy: 0.9793 - val_loss: 0.0739\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0141 - val_accuracy: 0.9740 - val_loss: 0.0982\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9740 - loss: 0.0982\n",
      "Test accuracy of baseline model: 0.9740\n"
     ]
    }
   ],
   "source": [
    "# Define the baseline model\n",
    "model_baseline = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images into a 1D array\n",
    "    keras.layers.Dense(128, activation='relu'),  # Hidden layer with 128 neurons and ReLU activation\n",
    "    keras.layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_baseline.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_baseline = model_baseline.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model_baseline.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test accuracy of baseline model: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L1 and L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 4.9877 - val_accuracy: 0.8507 - val_loss: 1.1948\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8513 - loss: 1.1644 - val_accuracy: 0.8709 - val_loss: 1.0463\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 1.0672 - val_accuracy: 0.8583 - val_loss: 1.0237\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 1.0069 - val_accuracy: 0.8692 - val_loss: 0.9892\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.9780 - val_accuracy: 0.8780 - val_loss: 0.9396\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.9481 - val_accuracy: 0.8827 - val_loss: 0.9204\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.9302 - val_accuracy: 0.8862 - val_loss: 0.8777\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.9237 - val_accuracy: 0.8867 - val_loss: 0.8824\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.9181 - val_accuracy: 0.8798 - val_loss: 0.8897\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8780 - loss: 0.9016 - val_accuracy: 0.8902 - val_loss: 0.8555\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.8902 - loss: 0.8555\n",
      "Test accuracy with L1 regularization: 0.8902\n"
     ]
    }
   ],
   "source": [
    "# Import regularization functions\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "# Define the model with L1 regularization\n",
    "model_l1_l2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images into a 1D array\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=l1(0.01)),  # L1 regularization\n",
    "    keras.layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_l1_l2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_l1_l2 = model_l1_l2.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss_l1_l2, test_acc_l1_l2 = model_l1_l2.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test accuracy with L1 regularization: {test_acc_l1_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.9630 - val_accuracy: 0.9342 - val_loss: 0.3940\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.4064 - val_accuracy: 0.9383 - val_loss: 0.3718\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.3645 - val_accuracy: 0.9473 - val_loss: 0.3246\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9418 - loss: 0.3387 - val_accuracy: 0.9524 - val_loss: 0.3091\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.3196 - val_accuracy: 0.9441 - val_loss: 0.3179\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.3066 - val_accuracy: 0.9562 - val_loss: 0.2856\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.3009 - val_accuracy: 0.9505 - val_loss: 0.2941\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9527 - loss: 0.2870 - val_accuracy: 0.9525 - val_loss: 0.2801\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9528 - loss: 0.2838 - val_accuracy: 0.9584 - val_loss: 0.2651\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.2811 - val_accuracy: 0.9351 - val_loss: 0.3362\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9351 - loss: 0.3362\n",
      "Test accuracy with L2 regularization: 0.9351\n"
     ]
    }
   ],
   "source": [
    "# Define the model with L2 regularization\n",
    "model_l2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images into a 1D array\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  # L2 regularization\n",
    "    keras.layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_l2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_l2 = model_l2.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss_l2, test_acc_l2 = model_l2.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test accuracy with L2 regularization: {test_acc_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L2 Performs better than L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine L1 and L2 (Elastic Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7581 - loss: 5.1172 - val_accuracy: 0.8304 - val_loss: 1.2661\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8495 - loss: 1.1865 - val_accuracy: 0.8554 - val_loss: 1.0835\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 1.0899 - val_accuracy: 0.8691 - val_loss: 1.0149\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8634 - loss: 1.0303 - val_accuracy: 0.8761 - val_loss: 0.9565\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.9908 - val_accuracy: 0.8567 - val_loss: 0.9802\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8692 - loss: 0.9614 - val_accuracy: 0.8814 - val_loss: 0.9177\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.9445 - val_accuracy: 0.8877 - val_loss: 0.8950\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.9423 - val_accuracy: 0.8775 - val_loss: 0.9235\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.9219 - val_accuracy: 0.8949 - val_loss: 0.8571\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8810 - loss: 0.8986 - val_accuracy: 0.8954 - val_loss: 0.8441\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.8954 - loss: 0.8441\n",
      "Test accuracy with L1 + L2 (Elastic Net) regularization: 0.8954\n"
     ]
    }
   ],
   "source": [
    "# Import the correct function\n",
    "from tensorflow.keras.regularizers import l1_l2  \n",
    "\n",
    "# Define a model with L1 + L2 regularization (Elastic Net)\n",
    "model_l1_l2_combined = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images into a 1D array\n",
    "    keras.layers.Dense(128, activation='relu', \n",
    "                       kernel_regularizer=l1_l2(l1=0.01, l2=0.01)),  # L1 + L2 regularization\n",
    "    keras.layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_l1_l2_combined.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_l1_l2_combined = model_l1_l2_combined.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_l1_l2_combined, test_acc_l1_l2_combined = model_l1_l2_combined.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test accuracy with L1 + L2 (Elastic Net) regularization: {test_acc_l1_l2_combined:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of L1 + L2 (Elastic Net) Regularization Results\n",
    "Training Accuracy: 88.10%\n",
    "\n",
    "Validation Accuracy: 89.54%\n",
    "\n",
    "Training Loss: 0.8986\n",
    "\n",
    "Validation Loss: 0.8441\n",
    "\n",
    "Observations: Better generalization than using L1 alone but still lower than L2 alone (95.59%).\n",
    "\n",
    "Validation accuracy improved compared to L1, but still lower than L2. Higher loss compared to L2, which suggests L1 is shrinking too many weights aggressively.\n",
    "\n",
    "Conclusion: L2 regularization alone gave the best performance so far, but Elastic Net might be useful when feature selection is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8138 - loss: 0.6104 - val_accuracy: 0.9520 - val_loss: 0.1590\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2376 - val_accuracy: 0.9613 - val_loss: 0.1287\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1883 - val_accuracy: 0.9678 - val_loss: 0.1112\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1609 - val_accuracy: 0.9677 - val_loss: 0.1049\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9525 - loss: 0.1565 - val_accuracy: 0.9695 - val_loss: 0.0983\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9578 - loss: 0.1400 - val_accuracy: 0.9732 - val_loss: 0.0895\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9564 - loss: 0.1401 - val_accuracy: 0.9762 - val_loss: 0.0851\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9620 - loss: 0.1217 - val_accuracy: 0.9753 - val_loss: 0.0811\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9622 - loss: 0.1221 - val_accuracy: 0.9733 - val_loss: 0.0877\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9638 - loss: 0.1127 - val_accuracy: 0.9767 - val_loss: 0.0836\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.9767 - loss: 0.0836\n",
      "Test accuracy with Dropout regularization: 0.9767\n"
     ]
    }
   ],
   "source": [
    "# Define a model with Dropout regularization\n",
    "model_dropout = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images into a 1D array\n",
    "    keras.layers.Dense(128, activation='relu'),  # Fully connected layer with ReLU activation\n",
    "    keras.layers.Dropout(0.5),  # Dropout layer with 50% dropout rate\n",
    "    keras.layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_dropout.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_dropout = model_dropout.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_dropout, test_acc_dropout = model_dropout.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test accuracy with Dropout regularization: {test_acc_dropout:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Dropout Regularization Results\n",
    "\n",
    "Training Accuracy: 96.38%\n",
    "\n",
    "Validation Accuracy: 97.67%\n",
    "\n",
    "Training Loss: 0.1127\n",
    "\n",
    "Validation Loss: 0.0836\n",
    "\n",
    "Observations:\n",
    "Dropout significantly reduced overfitting compared to the baseline model. The validation accuracy is very close to training accuracy.\n",
    "\n",
    "Performance is better than L1, L2, and Elastic Net, achieving one of the highest test accuracies so far.\n",
    "\n",
    "Dropout introduces some randomness, which can slightly slow down training but improves generalization.\n",
    "\n",
    "Conclusion: Dropout has been the most effective regularization technique so far, improving generalization while maintaining high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.6137 - val_accuracy: 0.9481 - val_loss: 0.1711\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.2372 - val_accuracy: 0.9611 - val_loss: 0.1275\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.1966 - val_accuracy: 0.9653 - val_loss: 0.1129\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.1670 - val_accuracy: 0.9695 - val_loss: 0.1050\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9544 - loss: 0.1509 - val_accuracy: 0.9710 - val_loss: 0.0965\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9558 - loss: 0.1427 - val_accuracy: 0.9727 - val_loss: 0.0901\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.1304 - val_accuracy: 0.9749 - val_loss: 0.0892\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1266 - val_accuracy: 0.9745 - val_loss: 0.0893\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9623 - loss: 0.1224 - val_accuracy: 0.9733 - val_loss: 0.0907\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9629 - loss: 0.1160 - val_accuracy: 0.9761 - val_loss: 0.0883\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.1114 - val_accuracy: 0.9754 - val_loss: 0.0900\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.1069 - val_accuracy: 0.9760 - val_loss: 0.0940\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.1082 - val_accuracy: 0.9760 - val_loss: 0.0894\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.9761 - loss: 0.0883\n",
      "Test accuracy with Dropout + Early Stopping: 0.9761\n"
     ]
    }
   ],
   "source": [
    "# Import EarlyStopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define a model with Dropout regularization\n",
    "model_early_stopping = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images into a 1D array\n",
    "    keras.layers.Dense(128, activation='relu'),  # Fully connected layer with ReLU activation\n",
    "    keras.layers.Dropout(0.5),  # Dropout layer with 50% dropout rate\n",
    "    keras.layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_early_stopping.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=3,  # Stop training if validation loss doesn't improve for 3 epochs\n",
    "    restore_best_weights=True  # Restore best model weights after stopping\n",
    ")\n",
    "\n",
    "# Train the model with EarlyStopping\n",
    "history_early_stopping = model_early_stopping.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=20,  # Set maximum number of epochs\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]  # Apply EarlyStopping callback\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_early_stopping, test_acc_early_stopping = model_early_stopping.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test accuracy with Dropout + Early Stopping: {test_acc_early_stopping:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Dropout + Early Stopping Results\n",
    "\n",
    "Training Accuracy: 96.66%\n",
    "\n",
    "Validation Accuracy: 97.60%\n",
    "\n",
    "Training Loss: 0.1082\n",
    "\n",
    "Validation Loss: 0.0894\n",
    "\n",
    "Stopped at Epoch: 13 (before 20, preventing overfitting)\n",
    "\n",
    "Observations: Early Stopping prevented unnecessary training, stopping at epoch 13 when validation loss stopped improving.\n",
    "\n",
    "Performance is almost identical to Dropout alone, but faster training (no wasted epochs).\n",
    "\n",
    "Best generalization so far! The accuracy is high, and overfitting is minimal.\n",
    "Conclusion: Dropout + Early Stopping is the best combination yet! It balances high accuracy with efficient training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eakes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.6132 - loss: 1.1796 - val_accuracy: 0.9384 - val_loss: 0.2413\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8296 - loss: 0.5560 - val_accuracy: 0.9551 - val_loss: 0.1659\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8540 - loss: 0.4727 - val_accuracy: 0.9620 - val_loss: 0.1344\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8663 - loss: 0.4399 - val_accuracy: 0.9646 - val_loss: 0.1240\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8735 - loss: 0.4199 - val_accuracy: 0.9650 - val_loss: 0.1096\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8778 - loss: 0.4067 - val_accuracy: 0.9670 - val_loss: 0.1046\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8844 - loss: 0.3845 - val_accuracy: 0.9709 - val_loss: 0.1018\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8842 - loss: 0.3837 - val_accuracy: 0.9677 - val_loss: 0.1097\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.3673 - val_accuracy: 0.9740 - val_loss: 0.0957\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8896 - loss: 0.3606 - val_accuracy: 0.9728 - val_loss: 0.0928\n",
      "313/313 - 0s - 901us/step - accuracy: 0.9728 - loss: 0.0928\n",
      "Test accuracy with Data Augmentation: 0.9728\n"
     ]
    }
   ],
   "source": [
    "# Import ImageDataGenerator for data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,        # Rotate images by up to 10 degrees\n",
    "    width_shift_range=0.1,    # Shift images horizontally by up to 10% of width\n",
    "    height_shift_range=0.1,   # Shift images vertically by up to 10% of height\n",
    "    zoom_range=0.1            # Zoom in/out by up to 10%\n",
    ")\n",
    "\n",
    "# Define the neural network model\n",
    "model_data_aug = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten 28x28 images into a 1D array\n",
    "    keras.layers.Dense(128, activation='relu'),  # Fully connected layer with ReLU activation\n",
    "    keras.layers.Dropout(0.5),  # Dropout layer with 50% dropout rate\n",
    "    keras.layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_data_aug.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Create the augmented training data generator\n",
    "train_generator = datagen.flow(\n",
    "    x_train.reshape(-1, 28, 28, 1),  # Reshape input images to (batch_size, 28, 28, 1)\n",
    "    y_train,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Train the model with data augmentation\n",
    "history_data_aug = model_data_aug.fit(\n",
    "    train_generator,  # Use augmented data for training\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_data_aug, test_acc_data_aug = model_data_aug.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test accuracy with Data Augmentation: {test_acc_data_aug:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Data Augmentation Results\n",
    "\n",
    "Training Accuracy: 88.96%\n",
    "\n",
    "Validation Accuracy: 97.28%\n",
    "\n",
    "Training Loss: 0.3606\n",
    "\n",
    "Validation Loss: 0.0928\n",
    "\n",
    "Observations:\n",
    "\n",
    "-Better generalization than the baseline model, preventing overfitting by exposing the model to slightly altered images. -High validation accuracy (97.28%), close to Dropout + Early Stopping (97.60%). -Slower training due to real-time image transformations.\n",
    "\n",
    "-Conclusion: Data Augmentation improved generalization but took more time to train. It is useful when working with small datasets or wanting to improve model robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine Regularization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eakes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\eakes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5830 - loss: 1.8507 - val_accuracy: 0.9147 - val_loss: 0.6838\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7554 - loss: 1.0648 - val_accuracy: 0.9266 - val_loss: 0.5901\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7772 - loss: 0.9905 - val_accuracy: 0.9386 - val_loss: 0.5612\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7898 - loss: 0.9437 - val_accuracy: 0.9356 - val_loss: 0.5406\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7969 - loss: 0.9229 - val_accuracy: 0.9402 - val_loss: 0.5130\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8025 - loss: 0.9097 - val_accuracy: 0.9437 - val_loss: 0.5011\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7993 - loss: 0.9036 - val_accuracy: 0.9402 - val_loss: 0.5153\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8008 - loss: 0.9095 - val_accuracy: 0.9489 - val_loss: 0.4905\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8060 - loss: 0.8943 - val_accuracy: 0.9504 - val_loss: 0.4783\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8031 - loss: 0.8965 - val_accuracy: 0.9385 - val_loss: 0.5153\n",
      "313/313 - 0s - 736us/step - accuracy: 0.9385 - loss: 0.5153\n",
      "Test accuracy with L2 + Dropout + Data Augmentation: 0.9385\n"
     ]
    }
   ],
   "source": [
    "# Define the model combining L2 Regularization, Dropout, and Data Augmentation\n",
    "model_combined = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),  # Flatten 28x28 images into a 1D array\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  # L2 regularization\n",
    "    keras.layers.Dropout(0.5),  # Dropout layer with 50% dropout rate\n",
    "    keras.layers.Dense(10, activation='softmax')  # Output layer with 10 neurons (for 10 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_combined.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Create the augmented training data generator\n",
    "train_generator_combined = datagen.flow(\n",
    "    x_train.reshape(-1, 28, 28, 1),  # Reshape input images to (batch_size, 28, 28, 1)\n",
    "    y_train,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Train the model with L2, Dropout, and Data Augmentation\n",
    "history_combined = model_combined.fit(\n",
    "    train_generator_combined,  # Use augmented data for training\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss_combined, test_acc_combined = model_combined.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Print test accuracy\n",
    "print(f\"Test accuracy with L2 + Dropout + Data Augmentation: {test_acc_combined:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
